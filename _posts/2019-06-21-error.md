
We can determine the expected value of a prediction by taking the squared difference between actual response $Y$ and predicted response $\hat{Y}$.

\begin{equation}\label{eq_error}
E(Y-\hat{Y})^2 = E[f(X)+\epsilon - \hat{f}(X)]^2
\end{equation}

where
- $Y$ is a response
- $X$ is a set of predictors
- $f$ is a function 
- $\epsilon$ is an error term

and
- $\hat{Y}$ is a resulting prediction for response $Y$
- $\hat{f}$ is an estimate of $f$

The equation above shows the squared difference between $Y$ and $\hat{Y}$. Doing so determines the expected value of the difference between function $f$ of predictor $X$ with error $\epsilon$ subtracting the estimated function $\hat{f}$ of predictor $X$. Simplified as

\begin{equation}\label{eq_errorsimplified}
E(Y-\hat{Y})^2 = E[f(X) - \hat{f}(X)]^2 + \text{Var}(\epsilon) 
\end{equation}

where
- $E(Y-\hat{Y})^2$ is the *expected value* of the squared difference between $Y$ and $\hat{Y}$.
- $E[f(X) - \hat{f}(X)]^2$ is a reducible error. To be minimized when estimating $f$.
- $\text{Var}(\epsilon)$ is an irreducible error. Also the variance associated with $\epsilon$.

The equation above shows the simplified version, leading to having two types of error: reducible and irreducible. The reducible error becomes the goal of prediction. The irreducible error takes into account the error present in actual response $Y$.

## Reference

James, G., Witten, D., Hastie, T., & Tibshirani, R. (2013). An Introduction to Statistical Learning (Vol. 103). https://doi.org/10.1007/978-1-4614-7138-7
